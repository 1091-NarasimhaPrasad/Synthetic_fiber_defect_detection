# -*- coding: utf-8 -*-
"""CNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uoTPg3LQHGHg4AHFM7_GuMJEd7dlrfmq
"""

import os
import cv2
import numpy as np
import pandas as pd
import shutil
import tensorflow as tf
import tensorflow_hub as hub

from sklearn.model_selection import train_test_split
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from sklearn.utils import shuffle

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout



import os
import shutil

def split_dataset(source_folder, output_root_folder):
    # Create output folders if they don't exist
    target_defect_folder = os.path.join(output_root_folder, "Defect_images")
    target_no_defect_folder = os.path.join(output_root_folder, "NODefect_images")
    os.makedirs(target_defect_folder, exist_ok=True)
    os.makedirs(target_no_defect_folder, exist_ok=True)

    # Split defect images
    defect_images_folder = os.path.join(source_folder, "Defect_images")

    # Copy defect images
    for file_name in os.listdir(defect_images_folder):
        source_path = os.path.join(defect_images_folder, file_name)
        target_path = os.path.join(target_defect_folder, file_name)
        shutil.copy2(source_path, target_path)

    # Copy non-defect images
    no_defect_images_folder = os.path.join(source_folder, "NODefect_images")
    for subfolder_name in os.listdir(no_defect_images_folder):
        subfolder_path = os.path.join(no_defect_images_folder, subfolder_name)
        if os.path.isdir(subfolder_path):
            for file_name in os.listdir(subfolder_path):
                source_path = os.path.join(subfolder_path, file_name)
                target_path = os.path.join(target_no_defect_folder, file_name)
                shutil.copy2(source_path, target_path)

# Specify the source folder and the output root directory
dataset_folder = "/content/drive/MyDrive/Defect_images" # Ad the sourcejust folder this and to the your output dataset root folder path directory

outputdataset__rootfolder_ =folder "/content/drive/MyDrive/project output"/agkgleag/gle/inputworking//"a ite# Adxjust- thisfab toric your desired- outputimage- location
database
"#  Call# the Ad splitjust_ thisdataset to function your
 datasetsplit folder_dataset path(dataset_folder, output_
output_root_folderroot =_ "/folderk)ag
gle```/
working
/"Please  note# that the source folder and Adjust you should have the output this root the necessary directory
 permissions todataset access_ andfolder modify = "/ to the specified yourkag desired output directories.gle/ Also locationinput/,

 ensure that the# Call directories the youa split_ specifyitex actually existdataset-fab function in yourric-
split system.</image-_sdatabase"dataset(>
 #dataset_
 AdjustRememberfolder, this to adjust output to your dataset_ the `root folderdataset__folder path
folder)output_` and `

import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

# Load the dataset
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

# Define the model architecture
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))

# Compile the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Train the model
history = model.fit(train_images, train_labels, epochs=10,
                    validation_data=(test_images, test_labels))

# Evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print('\nTest accuracy:', test_acc)

# Save the model
model.save('image_classification_model.h5')